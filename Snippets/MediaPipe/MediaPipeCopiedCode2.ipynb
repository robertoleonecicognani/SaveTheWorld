{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMjyaWHj4bK9L7yLkJqx/PX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobertoAlessandri/SaveTheWorld/blob/main/MediaPipeCopiedCode2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFQfVF5Wui-G",
        "outputId": "214929ce-dd33-4311-a61f-c6c70136cda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.8.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.7 MB 141 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.11.4->mediapipe) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.6)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpPose = mp.solutions.pose\n",
        "pose = mpPose.Pose()\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "\n",
        "#cap = cv2.VideoCapture(0)\n",
        "cap = cv2.VideoCapture('a.mp4')\n",
        "pTime = 0\n",
        "\n",
        "while True:\n",
        "  success, img = cap.read()\n",
        "imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#\n",
        "results = pose.process(imgRGB)#\n",
        "print(results.pose_landmarks)#\n",
        "if results.pose_landmarks:\n",
        "  mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)#\n",
        "for id, lm in enumerate(results.pose_landmarks.landmark):\n",
        "  h, w,c = img.shape\n",
        "print(id, lm)#\n",
        "cx, cy = int(lm.x*w), int(lm.y*h)#\n",
        "cv2.circle(img, (cx, cy), 5, (255,0,0), cv2.FILLED)#\n",
        "\n",
        "cTime = time.time()\n",
        "fps = 1/(cTime-pTime)\n",
        "pTime = cTime\n",
        "\n",
        "cv2.putText(img, str(int(fps)), (50,50), cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0), 3)\n",
        "cv2.imshow(\"Image\", img)\n",
        "cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "BDny8motun8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PoseDetector:\n",
        "\n",
        "  def __init__(self, mode = False, upBody = False, smooth=True, detectionCon = 0.5, trackCon = 0.5):\n",
        "\n",
        "    self.mode = mode\n",
        "    self.upBody = upBody\n",
        "    self.smooth = smooth\n",
        "    self.detectionCon = detectionCon\n",
        "    self.trackCon = trackCon\n",
        "\n",
        "    self.mpDraw = mp.solutions.drawing_utils\n",
        "    self.mpPose = mp.solutions.pose\n",
        "    self.pose = self.mpPose.Pose(self.mode, self.upBody, self.smooth, self.detectionCon, self.trackCon)\n",
        "\n",
        "  def findPose(self, img, draw=True):\n",
        "    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    self.results = self.pose.process(imgRGB)\n",
        "    #print(results.pose_landmarks)\n",
        "    # after the input frames are taken, mpDraw will draw the landmarks across \n",
        "    # the body\n",
        "    if self.results.pose_landmarks:\n",
        "      if draw:\n",
        "        self.mpDraw.draw_landmarks(img, self.results.pose_landmarks, self.mpPose.POSE_CONNECTIONS)\n",
        "\n",
        "  return img\n",
        "\n",
        "  def getPosition(self, img, draw=True):\n",
        "    lmList= []\n",
        "    if self.results.pose_landmarks:\n",
        "      for id, lm in enumerate(self.results.pose_landmarks.landmark):\n",
        "        h, w, c = img.shape\n",
        "        #print(id, lm)\n",
        "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "        lmList.append([id, cx, cy])\n",
        "    if draw:\n",
        "      cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
        "  return lmList\n",
        "\n",
        "  def main():\n",
        "    cap = cv2.VideoCapture('videos/a.mp4') #make VideoCapture(0) for webcam\n",
        "    pTime = 0\n",
        "    detector = PoseDetector()\n",
        "    while True:\n",
        "      success, img = cap.read()\n",
        "      img = detector.findPose(img)\n",
        "      lmList = detector.getPosition(img)\n",
        "    print(lmList)\n",
        "\n",
        "  cTime = time.time()\n",
        "  fps = 1 / (cTime - pTime)\n",
        "  pTime = cTime\n",
        "\n",
        "  cv2.putText(img, str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
        "  cv2.imshow(\"Image\", img)\n",
        "  cv2.waitKey(1)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  main() "
      ],
      "metadata": {
        "id": "QgPpzDcKuv1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "pTime = 0\n",
        "detector = pm.PoseDetector()\n",
        "while True:\n",
        "  success, img = cap.read()\n",
        "img = detector.findPose(img)#\n",
        "lmList = detector.getPosition(img)#\n",
        "print(lmList)#\n",
        "\n",
        "cTime = time.time()\n",
        "fps = 1 / (cTime - pTime)\n",
        "pTime = cTime\n",
        "\n",
        "cv2.putText(img, str(int(fps)), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
        "cv2.imshow(\"Image\", img)\n",
        "cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "1Wjesz90vGvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}